{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa0ac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d6e5b20",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3041bece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91d77184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5a2c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_csv = pd.read_csv('Train_Data.csv')\n",
    "# cv_dataset = pd.read_csv('CV_Data.csv')\n",
    "# test_dataset = pd.read_csv('Test_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f8d56dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "2758\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person_id</th>\n",
       "      <th>Image1</th>\n",
       "      <th>Image2</th>\n",
       "      <th>Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR1_1_IM-0001_0</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR1_1_IM-0001-3001.png</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR1_1_IM-0001-4001.png</td>\n",
       "      <td>the cardiac silhouette and mediastinum size ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR10_IM-0002_0</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR10_IM-0002-1001.png</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR10_IM-0002-2001.png</td>\n",
       "      <td>the cardiomediastinal silhouette within normal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR100_IM-0002_0</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR100_IM-0002-1001.png</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR100_IM-0002-2001.png</td>\n",
       "      <td>both lungs are clear and epanded .  heart and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003_0</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003-1001...</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003-2001...</td>\n",
       "      <td>there increased opacity within the right upper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003_1</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003-1001...</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003-3001...</td>\n",
       "      <td>there increased opacity within the right upper...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Person_id  \\\n",
       "0   ../data/NLMCXR/NLMCXR_png/CXR1_1_IM-0001_0   \n",
       "1    ../data/NLMCXR/NLMCXR_png/CXR10_IM-0002_0   \n",
       "2   ../data/NLMCXR/NLMCXR_png/CXR100_IM-0002_0   \n",
       "3  ../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003_0   \n",
       "4  ../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003_1   \n",
       "\n",
       "                                              Image1  \\\n",
       "0  ../data/NLMCXR/NLMCXR_png/CXR1_1_IM-0001-3001.png   \n",
       "1   ../data/NLMCXR/NLMCXR_png/CXR10_IM-0002-1001.png   \n",
       "2  ../data/NLMCXR/NLMCXR_png/CXR100_IM-0002-1001.png   \n",
       "3  ../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003-1001...   \n",
       "4  ../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003-1001...   \n",
       "\n",
       "                                              Image2  \\\n",
       "0  ../data/NLMCXR/NLMCXR_png/CXR1_1_IM-0001-4001.png   \n",
       "1   ../data/NLMCXR/NLMCXR_png/CXR10_IM-0002-2001.png   \n",
       "2  ../data/NLMCXR/NLMCXR_png/CXR100_IM-0002-2001.png   \n",
       "3  ../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003-2001...   \n",
       "4  ../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003-3001...   \n",
       "\n",
       "                                              Report  \n",
       "0  the cardiac silhouette and mediastinum size ar...  \n",
       "1  the cardiomediastinal silhouette within normal...  \n",
       "2  both lungs are clear and epanded .  heart and ...  \n",
       "3  there increased opacity within the right upper...  \n",
       "4  there increased opacity within the right upper...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(train_dataset_csv))\n",
    "print(len(train_dataset_csv))\n",
    "train_dataset_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e443bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person_id</th>\n",
       "      <th>Image1</th>\n",
       "      <th>Image2</th>\n",
       "      <th>Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR1_1_IM-0001_0</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR1_1_IM-0001-3001.png</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR1_1_IM-0001-4001.png</td>\n",
       "      <td>the cardiac silhouette and mediastinum size ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR10_IM-0002_0</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR10_IM-0002-1001.png</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR10_IM-0002-2001.png</td>\n",
       "      <td>the cardiomediastinal silhouette within normal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR100_IM-0002_0</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR100_IM-0002-1001.png</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR100_IM-0002-2001.png</td>\n",
       "      <td>both lungs are clear and epanded .  heart and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003_0</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003-1001...</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003-2001...</td>\n",
       "      <td>there increased opacity within the right upper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003_1</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003-1001...</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003-3001...</td>\n",
       "      <td>there increased opacity within the right upper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2753</th>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR3682_IM-1834_0</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR3682_IM-1834-1001...</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR3682_IM-1834-2001...</td>\n",
       "      <td>the lungs are hypoventilated .  there no focal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR3683_IM-1835_0</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR3683_IM-1835-3001...</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR3683_IM-1835-4001...</td>\n",
       "      <td>eamination was performed with nipple markers ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR3685_IM-1836_0</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR3685_IM-1836-1001...</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR3685_IM-1836-1002...</td>\n",
       "      <td>calcified thoracic aorta .  mild rightward dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR3687_IM-1838_0</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR3687_IM-1838-1001...</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR3687_IM-1838-2001...</td>\n",
       "      <td>heart size and mediastinal contours are within...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR3689_IM-1840_0</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR3689_IM-1840-1001...</td>\n",
       "      <td>../data/NLMCXR/NLMCXR_png/CXR3689_IM-1840-2001...</td>\n",
       "      <td>normal heart size and mediastinal contours .  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2758 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Person_id  \\\n",
       "0      ../data/NLMCXR/NLMCXR_png/CXR1_1_IM-0001_0   \n",
       "1       ../data/NLMCXR/NLMCXR_png/CXR10_IM-0002_0   \n",
       "2      ../data/NLMCXR/NLMCXR_png/CXR100_IM-0002_0   \n",
       "3     ../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003_0   \n",
       "4     ../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003_1   \n",
       "...                                           ...   \n",
       "2753  ../data/NLMCXR/NLMCXR_png/CXR3682_IM-1834_0   \n",
       "2754  ../data/NLMCXR/NLMCXR_png/CXR3683_IM-1835_0   \n",
       "2755  ../data/NLMCXR/NLMCXR_png/CXR3685_IM-1836_0   \n",
       "2756  ../data/NLMCXR/NLMCXR_png/CXR3687_IM-1838_0   \n",
       "2757  ../data/NLMCXR/NLMCXR_png/CXR3689_IM-1840_0   \n",
       "\n",
       "                                                 Image1  \\\n",
       "0     ../data/NLMCXR/NLMCXR_png/CXR1_1_IM-0001-3001.png   \n",
       "1      ../data/NLMCXR/NLMCXR_png/CXR10_IM-0002-1001.png   \n",
       "2     ../data/NLMCXR/NLMCXR_png/CXR100_IM-0002-1001.png   \n",
       "3     ../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003-1001...   \n",
       "4     ../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003-1001...   \n",
       "...                                                 ...   \n",
       "2753  ../data/NLMCXR/NLMCXR_png/CXR3682_IM-1834-1001...   \n",
       "2754  ../data/NLMCXR/NLMCXR_png/CXR3683_IM-1835-3001...   \n",
       "2755  ../data/NLMCXR/NLMCXR_png/CXR3685_IM-1836-1001...   \n",
       "2756  ../data/NLMCXR/NLMCXR_png/CXR3687_IM-1838-1001...   \n",
       "2757  ../data/NLMCXR/NLMCXR_png/CXR3689_IM-1840-1001...   \n",
       "\n",
       "                                                 Image2  \\\n",
       "0     ../data/NLMCXR/NLMCXR_png/CXR1_1_IM-0001-4001.png   \n",
       "1      ../data/NLMCXR/NLMCXR_png/CXR10_IM-0002-2001.png   \n",
       "2     ../data/NLMCXR/NLMCXR_png/CXR100_IM-0002-2001.png   \n",
       "3     ../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003-2001...   \n",
       "4     ../data/NLMCXR/NLMCXR_png/CXR1000_IM-0003-3001...   \n",
       "...                                                 ...   \n",
       "2753  ../data/NLMCXR/NLMCXR_png/CXR3682_IM-1834-2001...   \n",
       "2754  ../data/NLMCXR/NLMCXR_png/CXR3683_IM-1835-4001...   \n",
       "2755  ../data/NLMCXR/NLMCXR_png/CXR3685_IM-1836-1002...   \n",
       "2756  ../data/NLMCXR/NLMCXR_png/CXR3687_IM-1838-2001...   \n",
       "2757  ../data/NLMCXR/NLMCXR_png/CXR3689_IM-1840-2001...   \n",
       "\n",
       "                                                 Report  \n",
       "0     the cardiac silhouette and mediastinum size ar...  \n",
       "1     the cardiomediastinal silhouette within normal...  \n",
       "2     both lungs are clear and epanded .  heart and ...  \n",
       "3     there increased opacity within the right upper...  \n",
       "4     there increased opacity within the right upper...  \n",
       "...                                                 ...  \n",
       "2753  the lungs are hypoventilated .  there no focal...  \n",
       "2754  eamination was performed with nipple markers ....  \n",
       "2755  calcified thoracic aorta .  mild rightward dev...  \n",
       "2756  heart size and mediastinal contours are within...  \n",
       "2757  normal heart size and mediastinal contours .  ...  \n",
       "\n",
       "[2758 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('Train_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bbc3290",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "class DatasetFromCSV(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        # 读取csv文件\n",
    "        self.data_info = pd.read_csv(csv_path)# 去掉header=None，会读取表头\n",
    "        #第一列为person_id，以下都为一个列表\n",
    "        self.person_id = np.asarray(self.data_info.iloc[:, 0])\n",
    "        self.image1 = np.asarray(self.data_info.iloc[:,1])\n",
    "        self.image2 = np.asarray(self.data_info.iloc[:,2])\n",
    "        self.report = np.asarray(self.data_info.iloc[:,3])\n",
    "        # 长度，train=2758\n",
    "        self.data_len = len(self.data_info.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        singel_person_id=self.person_id[index]\n",
    "        singel_image1=Image.open(self.image1[index])\n",
    "        singel_image2=Image.open(self.image2[index])\n",
    "        singel_report=self.report[index]\n",
    "        \n",
    "        transf=transforms.Compose([transforms.Resize((224,224)),\n",
    "                                   transforms.ToTensor(),\n",
    "                                  ])\n",
    "        singel_image1=transf(singel_image1)\n",
    "        singel_image2=transf(singel_image2)\n",
    "        ##把图片标签也变成tensor类型\n",
    "#         singel_report=torch.tensor(singel_report)\n",
    "\n",
    "#         # Transform image to tensor\n",
    "#         img_as_tensor = self.to_tensor(img_as_img)\n",
    "#         # Get label of the image based on the cropped pandas column\n",
    "#         single_image_label = self.label_arr[index]\n",
    "#         return singel_person_id,singel_image1\n",
    "        return [singel_image1,singel_image2], singel_report, singel_person_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a502547",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7f070ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DatasetFromCSV('Train_Data.csv')\n",
    "cv_dataset = DatasetFromCSV('CV_Data.csv')\n",
    "test_dataset = DatasetFromCSV('Test_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0579ebca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[[0.0627, 0.0627, 0.0627,  ..., 0.6941, 0.6863, 0.7020],\n",
       "           [0.0627, 0.0627, 0.0627,  ..., 0.6863, 0.6824, 0.6745],\n",
       "           [0.0627, 0.0627, 0.0627,  ..., 0.6863, 0.6902, 0.6824],\n",
       "           ...,\n",
       "           [0.4588, 0.4824, 0.5020,  ..., 0.0471, 0.0510, 0.0510],\n",
       "           [0.4392, 0.4510, 0.4627,  ..., 0.1451, 0.1490, 0.1529],\n",
       "           [0.3647, 0.3765, 0.3961,  ..., 0.2980, 0.3020, 0.3059]],\n",
       "  \n",
       "          [[0.0627, 0.0627, 0.0627,  ..., 0.6941, 0.6863, 0.7020],\n",
       "           [0.0627, 0.0627, 0.0627,  ..., 0.6863, 0.6824, 0.6745],\n",
       "           [0.0627, 0.0627, 0.0627,  ..., 0.6863, 0.6902, 0.6824],\n",
       "           ...,\n",
       "           [0.4588, 0.4824, 0.5020,  ..., 0.0471, 0.0510, 0.0510],\n",
       "           [0.4392, 0.4510, 0.4627,  ..., 0.1451, 0.1490, 0.1529],\n",
       "           [0.3647, 0.3765, 0.3961,  ..., 0.2980, 0.3020, 0.3059]],\n",
       "  \n",
       "          [[0.0627, 0.0627, 0.0627,  ..., 0.6941, 0.6863, 0.7020],\n",
       "           [0.0627, 0.0627, 0.0627,  ..., 0.6863, 0.6824, 0.6745],\n",
       "           [0.0627, 0.0627, 0.0627,  ..., 0.6863, 0.6902, 0.6824],\n",
       "           ...,\n",
       "           [0.4588, 0.4824, 0.5020,  ..., 0.0471, 0.0510, 0.0510],\n",
       "           [0.4392, 0.4510, 0.4627,  ..., 0.1451, 0.1490, 0.1529],\n",
       "           [0.3647, 0.3765, 0.3961,  ..., 0.2980, 0.3020, 0.3059]]]),\n",
       "  tensor([[[0.1059, 0.0863, 0.0745,  ..., 0.0196, 0.0078, 0.0039],\n",
       "           [0.0941, 0.0706, 0.0627,  ..., 0.1216, 0.0784, 0.0392],\n",
       "           [0.0863, 0.0627, 0.0549,  ..., 0.2196, 0.2078, 0.1843],\n",
       "           ...,\n",
       "           [0.5020, 0.4431, 0.3686,  ..., 0.1255, 0.1373, 0.1608],\n",
       "           [0.4941, 0.4392, 0.3882,  ..., 0.1412, 0.1647, 0.1804],\n",
       "           [0.5843, 0.5098, 0.4118,  ..., 0.1961, 0.2157, 0.2196]],\n",
       "  \n",
       "          [[0.1059, 0.0863, 0.0745,  ..., 0.0196, 0.0078, 0.0039],\n",
       "           [0.0941, 0.0706, 0.0627,  ..., 0.1216, 0.0784, 0.0392],\n",
       "           [0.0863, 0.0627, 0.0549,  ..., 0.2196, 0.2078, 0.1843],\n",
       "           ...,\n",
       "           [0.5020, 0.4431, 0.3686,  ..., 0.1255, 0.1373, 0.1608],\n",
       "           [0.4941, 0.4392, 0.3882,  ..., 0.1412, 0.1647, 0.1804],\n",
       "           [0.5843, 0.5098, 0.4118,  ..., 0.1961, 0.2157, 0.2196]],\n",
       "  \n",
       "          [[0.1059, 0.0863, 0.0745,  ..., 0.0196, 0.0078, 0.0039],\n",
       "           [0.0941, 0.0706, 0.0627,  ..., 0.1216, 0.0784, 0.0392],\n",
       "           [0.0863, 0.0627, 0.0549,  ..., 0.2196, 0.2078, 0.1843],\n",
       "           ...,\n",
       "           [0.5020, 0.4431, 0.3686,  ..., 0.1255, 0.1373, 0.1608],\n",
       "           [0.4941, 0.4392, 0.3882,  ..., 0.1412, 0.1647, 0.1804],\n",
       "           [0.5843, 0.5098, 0.4118,  ..., 0.1961, 0.2157, 0.2196]]])],\n",
       " 'the cardiomediastinal silhouette within normal limits for size and contour .  the lungs are normally inflated without evidence focal airspace disease pleural effusion pneumothora .  stable calcified granuloma within the right upper lung .  no acute bone abnormality . ',\n",
       " '../data/NLMCXR/NLMCXR_png/CXR10_IM-0002_0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3424006",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(dataset=train_dataset,\n",
    "                        batch_size=16,\n",
    "                        shuffle=True,\n",
    "                        drop_last=True,#!!!!!因为Expected input batch_size (4) to match target batch_size (16).错误的原因，暂时修改为TRUE\n",
    "                        num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a5ecbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader=DataLoader(dataset=test_dataset,\n",
    "                        batch_size=64,\n",
    "                        shuffle=True,\n",
    "                        drop_last=True,\n",
    "                        num_workers=0)\n",
    "cv_loader=DataLoader(dataset=cv_dataset,\n",
    "                        batch_size=64,\n",
    "                        shuffle=True,\n",
    "                        drop_last=True,\n",
    "                        num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ca1e372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RN50',\n",
       " 'RN101',\n",
       " 'RN50x4',\n",
       " 'RN50x16',\n",
       " 'RN50x64',\n",
       " 'ViT-B/32',\n",
       " 'ViT-B/16',\n",
       " 'ViT-L/14',\n",
       " 'ViT-L/14@336px']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import clip\n",
    "\n",
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c292b8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 151,277,313\n",
      "Input resolution: 224\n",
      "Context length: 77\n",
      "Vocab size: 49408\n"
     ]
    }
   ],
   "source": [
    "model, preprocess = clip.load(\"ViT-B/32\",device=device,jit=False,)\n",
    "# model.cuda().eval()\n",
    "input_resolution = model.visual.input_resolution\n",
    "context_length = model.context_length\n",
    "vocab_size = model.vocab_size\n",
    "\n",
    "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "print(\"Input resolution:\", input_resolution)\n",
    "print(\"Context length:\", context_length)\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "476f2595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=224, interpolation=bicubic, max_size=None, antialias=None)\n",
       "    CenterCrop(size=(224, 224))\n",
       "    <function _convert_image_to_rgb at 0x000002210DFA13A0>\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6268a3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f5bade3",
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "epoch = 15\n",
    "batch_size = 16\n",
    "learning_rate = 5e-5\n",
    "\n",
    "loss_img = nn.CrossEntropyLoss().to(device)\n",
    "loss_txt = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.98), eps=1e-6, weight_decay=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0adb97d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_models_to_fp32(model):\n",
    "    for p in model.parameters():\n",
    "        p.data = p.data.float()\n",
    "        p.grad.data = p.grad.data.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da1fa7e8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----[1] epoch---\n",
      "[1] loss: 2.791016\n",
      "----[2] epoch---\n",
      "[2] loss: 2.769531\n",
      "----[3] epoch---\n",
      "[3] loss: 2.775391\n",
      "----[4] epoch---\n",
      "[4] loss: 2.777344\n",
      "----[5] epoch---\n",
      "[5] loss: 2.777344\n",
      "----[6] epoch---\n",
      "[6] loss: 2.761719\n",
      "----[7] epoch---\n",
      "[7] loss: 2.769531\n",
      "----[8] epoch---\n",
      "[8] loss: 2.773438\n",
      "----[9] epoch---\n",
      "[9] loss: 2.773438\n",
      "----[10] epoch---\n",
      "[10] loss: 2.773438\n",
      "----[11] epoch---\n",
      "[11] loss: 2.773438\n",
      "----[12] epoch---\n",
      "[12] loss: 2.773438\n",
      "----[13] epoch---\n",
      "[13] loss: 2.773438\n",
      "----[14] epoch---\n",
      "[14] loss: 2.773438\n",
      "----[15] epoch---\n",
      "[15] loss: 2.773438\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    print('----[%d] epoch---' % (i + 1))\n",
    "    for batch in train_loader:\n",
    "\n",
    "        images, report, person_id = batch\n",
    "        report = clip.tokenize(texts=report, truncate=True).to(device)#truncate=True截断句子\n",
    "        # images = images.to(device)\n",
    "        image1 = images[0].to(device)\n",
    "        image2 = images[1].to(device)\n",
    "\n",
    "        # 通过logits_per_image, logits_per_text = model(images, texts)可以得到预测结果，与torch.arange(N)计算交叉熵进行优化\n",
    "        logits_per_image1, logits_per_text = model(image1, report)\n",
    "        if device == \"cpu\":\n",
    "            ground_truth = torch.arange(batch_size).long().to(device)\n",
    "            print(\"cpu\")\n",
    "        else:\n",
    "            ground_truth = torch.arange(batch_size, dtype=torch.long, device=device)\n",
    "\n",
    "        # 反向传播\n",
    "        total_loss = (loss_img(logits_per_image1, ground_truth) + loss_txt(logits_per_text, ground_truth)) / 2\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        if device == \"cpu\":\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            convert_models_to_fp32(model)\n",
    "            optimizer.step()\n",
    "            clip.model.convert_weights(model)\n",
    "\n",
    "    print('[%d] loss: %.6f' % (i + 1, total_loss))\n",
    "torch.save(model, 'D:/coding/Jupyter/CLIP-Medical Report Generation/notebooks/model1.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5f96449",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(torch.cuda, 'empty_cache'):\n",
    "\ttorch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8dc27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epoch):\n",
    "    print('----[%d] epoch---' % (i + 1))\n",
    "    for batch in train_loader:\n",
    "\n",
    "        images, report, person_id = batch\n",
    "        report = clip.tokenize(texts=report, truncate=True).to(device)#truncate=True截断句子\n",
    "        # images = images.to(device)\n",
    "        image1 = images[0].to(device)\n",
    "        image2 = images[1].to(device)\n",
    "\n",
    "        # 通过logits_per_image, logits_per_text = model(images, texts)可以得到预测结果，与torch.arange(N)计算交叉熵进行优化\n",
    "        logits_per_image1, logits_per_text = model(image1, report)\n",
    "        logits_per_image2, logits_per_text = model(image2, report)\n",
    "        logits_per_image = (logits_per_image1+logits_per_image2)/2\n",
    "        if device == \"cpu\":\n",
    "            ground_truth = torch.arange(batch_size).long().to(device)\n",
    "            print(\"cpu\")\n",
    "        else:\n",
    "            ground_truth = torch.arange(batch_size, dtype=torch.long, device=device)\n",
    "\n",
    "        # 反向传播\n",
    "        total_loss = (loss_img(logits_per_image, ground_truth) + loss_txt(logits_per_text, ground_truth)) / 2\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        if device == \"cpu\":\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            convert_models_to_fp32(model)\n",
    "            optimizer.step()\n",
    "            clip.model.convert_weights(model)\n",
    "\n",
    "    print('[%d] loss: %.6f' % (i + 1, total_loss))\n",
    "torch.save(model, 'D:/coding/Jupyter/CLIP-Medical Report Generation/notebooks/model2.pkl')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "notebooks///ipynb,notebooks/py///py"
  },
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
